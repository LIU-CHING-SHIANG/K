{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1241fb-9377-4f79-9d5e-4d274f02290d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置 matplotlib 字体以显示中文\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ---------------------------\n",
    "# 模型预测部分\n",
    "# ---------------------------\n",
    "\n",
    "class LightGBMModel:\n",
    "    @staticmethod\n",
    "    def shap_feature_importance(train_X, train_Y, params, isClassifier=True):\n",
    "        \"\"\"\n",
    "        使用 SHAP 计算特征重要性\n",
    "\n",
    "        :param train_X: 训练集特征\n",
    "        :param train_Y: 训练集标签\n",
    "        :param params: 模型参数\n",
    "        :param isClassifier: 是否为分类模型\n",
    "        :return: 特征重要性数据框、SHAP 值和模型\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isClassifier:\n",
    "                model = lgb.LGBMClassifier(**params)\n",
    "            else:\n",
    "                model = lgb.LGBMRegressor(**params)\n",
    "\n",
    "            model.fit(train_X, train_Y)\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(train_X)\n",
    "\n",
    "            # 计算特征重要性\n",
    "            mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "            feature_importance_df = pd.DataFrame({'Feature': train_X.columns, 'Importance': mean_abs_shap})\n",
    "            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "            return feature_importance_df, shap_values, model\n",
    "        except Exception as e:\n",
    "            print('shap_feature_importance has error: ' + str(e))\n",
    "            return None, None, None\n",
    "\n",
    "    @staticmethod\n",
    "    def grid_tune(train_X, train_Y, fold_time, param_grid, isClassifier=True):\n",
    "        \"\"\"\n",
    "        使用网格搜索进行参数调优\n",
    "\n",
    "        :param train_X: 训练集特征\n",
    "        :param train_Y: 训练集标签\n",
    "        :param fold_time: 交叉验证次数\n",
    "        :param param_grid: 参数网格\n",
    "        :param isClassifier: 是否为分类模型\n",
    "        :return: 最佳模型、最佳参数和交叉验证结果\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isClassifier:\n",
    "                model = lgb.LGBMClassifier()\n",
    "                scoring = 'accuracy'\n",
    "            else:\n",
    "                model = lgb.LGBMRegressor()\n",
    "                scoring = 'neg_mean_absolute_error'\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=fold_time)\n",
    "\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=tscv,\n",
    "                n_jobs=-1,\n",
    "                scoring=scoring,\n",
    "                verbose=1\n",
    "            )\n",
    "            grid_search.fit(train_X, train_Y)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "            return best_model, best_params, cv_results\n",
    "        except Exception as e:\n",
    "            print('grid_tune has error: ' + str(e))\n",
    "            return None, None, None\n",
    "\n",
    "    @staticmethod\n",
    "    def random_tune(train_X, train_Y, fold_time, param_distributions, isClassifier=True, n_iter=10):\n",
    "        \"\"\"\n",
    "        使用随机搜索进行参数调优\n",
    "\n",
    "        :param train_X: 训练集特征\n",
    "        :param train_Y: 训练集标签\n",
    "        :param fold_time: 交叉验证次数\n",
    "        :param param_distributions: 参数分布\n",
    "        :param isClassifier: 是否为分类模型\n",
    "        :param n_iter: 随机搜索迭代次数\n",
    "        :return: 最佳模型、最佳参数和交叉验证结果\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isClassifier:\n",
    "                model = lgb.LGBMClassifier()\n",
    "                scoring = 'accuracy'\n",
    "            else:\n",
    "                model = lgb.LGBMRegressor()\n",
    "                scoring = 'neg_mean_absolute_error'\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=fold_time)\n",
    "\n",
    "            random_search = RandomizedSearchCV(\n",
    "                estimator=model,\n",
    "                param_distributions=param_distributions,\n",
    "                cv=tscv,\n",
    "                n_jobs=-1,\n",
    "                scoring=scoring,\n",
    "                n_iter=n_iter,\n",
    "                verbose=1,\n",
    "                random_state=42\n",
    "            )\n",
    "            random_search.fit(train_X, train_Y)\n",
    "            best_model = random_search.best_estimator_\n",
    "            best_params = random_search.best_params_\n",
    "            cv_results = pd.DataFrame(random_search.cv_results_)\n",
    "            return best_model, best_params, cv_results\n",
    "        except Exception as e:\n",
    "            print('random_tune has error: ' + str(e))\n",
    "            return None, None, None\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('完整的合併資料.csv')\n",
    "\n",
    "# 将 'Date' 列转换为 datetime 类型\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# 确保数据按照 'ticker' 和 'Date' 排序\n",
    "df = df.sort_values(['ticker', 'Date']).reset_index(drop=True)\n",
    "\n",
    "# 定义目标变量和特征\n",
    "target = 'Adj_Close'  # 请替换为您的目标变量名称\n",
    "features = [col for col in df.columns if col not in ['Date', 'ticker', target]]\n",
    "\n",
    "def train_and_predict_single_ticker(group_df, shap_threshold=0.85, use_feature_selection=True):\n",
    "    # 确保数据按照日期排序\n",
    "    group_df = group_df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # 如果数据量太少，无法训练，则跳过\n",
    "    if len(group_df) < 20:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} 数据量不足，跳过\")\n",
    "        return None\n",
    "\n",
    "    # 使用前 80% 的数据作为训练集，后 20% 的数据作为测试集\n",
    "    split_index = int(len(group_df) * 0.8)\n",
    "    train = group_df.iloc[:split_index]\n",
    "    test = group_df.iloc[split_index:]\n",
    "\n",
    "    if len(test) == 0:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} 测试集为空，跳过\")\n",
    "        return None\n",
    "\n",
    "    X_train = train[features]\n",
    "    y_train = train[target]\n",
    "    X_test = test[features]\n",
    "    y_test = test[target]\n",
    "\n",
    "    # 模型参数（原始模型）\n",
    "    params = {\n",
    "        'boosting_type': 'dart',\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.05,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 7,\n",
    "        'verbose': 0,\n",
    "        'min_data_in_leaf': 5\n",
    "    }\n",
    "\n",
    "    # 1. 计算 SHAP 值（无论是否进行特征选择）\n",
    "    try:\n",
    "        feature_importance_df, shap_values, initial_model = LightGBMModel.shap_feature_importance(\n",
    "            X_train, y_train, params=params, isClassifier=False)\n",
    "        if feature_importance_df is not None:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - SHAP 计算成功\")\n",
    "        else:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - SHAP 计算失败\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - SHAP 计算异常: {str(e)}\")\n",
    "        feature_importance_df, shap_values, initial_model = None, None, None\n",
    "\n",
    "    if use_feature_selection and feature_importance_df is not None:\n",
    "        try:\n",
    "            # 计算累计贡献度\n",
    "            total_importance = feature_importance_df['Importance'].sum()\n",
    "            feature_importance_df['Cumulative'] = feature_importance_df['Importance'].cumsum() / total_importance\n",
    "            # 根据阈值选择特征\n",
    "            important_features = feature_importance_df[feature_importance_df['Cumulative'] <= shap_threshold]['Feature'].tolist()\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 选择的特征数量：{len(important_features)}\")\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 选择的特征：{important_features}\")\n",
    "            selected_features = important_features\n",
    "            # 筛选 shap_values\n",
    "            selected_feature_indices = [X_train.columns.get_loc(f) for f in selected_features]\n",
    "            shap_values_selected = shap_values[:, selected_feature_indices]\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 特征筛选失败: {str(e)}\")\n",
    "            selected_features = features.copy()\n",
    "            shap_values_selected = shap_values\n",
    "    else:\n",
    "        # 不进行特征选择，使用所有特征\n",
    "        selected_features = features.copy()\n",
    "        shap_values_selected = shap_values\n",
    "        if not use_feature_selection:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 未进行特征选择，使用所有特征\")\n",
    "\n",
    "    # 使用重要特征进行模型训练（原始模型）\n",
    "    X_train_important = X_train[selected_features]\n",
    "    X_test_important = X_test[selected_features]\n",
    "\n",
    "    # 1. 训练原始模型\n",
    "    try:\n",
    "        original_model = lgb.LGBMRegressor(**params)\n",
    "        original_model.fit(X_train_important, y_train)\n",
    "        y_pred_original = original_model.predict(X_test_important)\n",
    "        mae_original = mean_absolute_error(y_test, y_pred_original)\n",
    "        mape_original = mean_absolute_percentage_error(y_test, y_pred_original) * 100  # 转换为百分比\n",
    "        mae_original_train = mean_absolute_error(y_train, original_model.predict(X_train_important))\n",
    "        mape_original_train = mean_absolute_percentage_error(y_train, original_model.predict(X_train_important)) * 100  # 转换为百分比\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - 原始模型训练集 MAE: {mae_original_train}, MAPE: {mape_original_train}%\")\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - 原始模型测试集 MAE: {mae_original}, MAPE: {mape_original}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - 原始模型训练失败: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # 2. 参数调优 - 网格搜索\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.005, 0.01, 0.03, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 9, -1],\n",
    "        'num_leaves': [31, 63],\n",
    "        'n_estimators': [100, 200],\n",
    "        'boosting_type': ['gbdt', 'dart'],\n",
    "        'random_state': [7],\n",
    "    }\n",
    "\n",
    "    best_model_grid, best_params_grid, cv_results_grid = LightGBMModel.grid_tune(\n",
    "        X_train_important, y_train, fold_time=5, param_grid=param_grid, isClassifier=False)\n",
    "\n",
    "    if best_model_grid is not None:\n",
    "        try:\n",
    "            y_pred_grid = best_model_grid.predict(X_test_important)\n",
    "            mae_grid = mean_absolute_error(y_test, y_pred_grid)\n",
    "            mape_grid = mean_absolute_percentage_error(y_test, y_pred_grid) * 100  # 转换为百分比\n",
    "            mae_grid_train = mean_absolute_error(y_train, best_model_grid.predict(X_train_important))\n",
    "            mape_grid_train = mean_absolute_percentage_error(y_train, best_model_grid.predict(X_train_important)) * 100  # 转换为百分比\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Grid Search 训练集 MAE: {mae_grid_train}, MAPE: {mape_grid_train}%\")\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Grid Search 测试集 MAE: {mae_grid}, MAPE: {mape_grid}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Grid Search 预测失败: {str(e)}\")\n",
    "            mae_grid, mape_grid, mae_grid_train, mape_grid_train = None, None, None, None\n",
    "    else:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - Grid Search 未找到最佳模型，使用原始模型的预测结果。\")\n",
    "        best_model_grid = original_model\n",
    "        y_pred_grid = y_pred_original\n",
    "        mae_grid = mae_original\n",
    "        mape_grid = mape_original\n",
    "        mae_grid_train = mae_original_train\n",
    "        mape_grid_train = mape_original_train\n",
    "\n",
    "    # 3. 参数调优 - 随机搜索\n",
    "    param_dist = {\n",
    "        'learning_rate': [0.005, 0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 9, -1],\n",
    "        'num_leaves': [15, 31, 63, 127],\n",
    "        'n_estimators': [50, 100, 200, 500],\n",
    "        'min_child_samples': [5, 10, 20, 50],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'lambda_l1': [0, 0.01, 0.1, 1],\n",
    "        'lambda_l2': [0, 0.01, 0.1, 1],\n",
    "        'boosting_type': ['gbdt', 'dart'],\n",
    "        'random_state': [7],\n",
    "    }\n",
    "\n",
    "    best_model_random, best_params_random, cv_results_random = LightGBMModel.random_tune(\n",
    "        X_train_important, y_train, fold_time=5, param_distributions=param_dist, isClassifier=False, n_iter=100)\n",
    "\n",
    "    if best_model_random is not None:\n",
    "        try:\n",
    "            y_pred_random = best_model_random.predict(X_test_important)\n",
    "            mae_random = mean_absolute_error(y_test, y_pred_random)\n",
    "            mape_random = mean_absolute_percentage_error(y_test, y_pred_random) * 100  # 转换为百分比\n",
    "            mae_random_train = mean_absolute_error(y_train, best_model_random.predict(X_train_important))\n",
    "            mape_random_train = mean_absolute_percentage_error(y_train, best_model_random.predict(X_train_important)) * 100  # 转换为百分比\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Random Search 训练集 MAE: {mae_random_train}, MAPE: {mape_random_train}%\")\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Random Search 测试集 MAE: {mae_random}, MAPE: {mape_random}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Random Search 预测失败: {str(e)}\")\n",
    "            mae_random, mape_random, mae_random_train, mape_random_train = None, None, None, None\n",
    "    else:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - Random Search 未找到最佳模型，使用原始模型的预测结果。\")\n",
    "        best_model_random = original_model\n",
    "        y_pred_random = y_pred_original\n",
    "        mae_random = mae_original\n",
    "        mape_random = mape_original\n",
    "        mae_random_train = mae_original_train\n",
    "        mape_random_train = mape_original_train\n",
    "\n",
    "    # 选择 MAE 最小的模型\n",
    "    mae_values = {}\n",
    "    if mae_original is not None:\n",
    "        mae_values['original'] = mae_original\n",
    "    if mae_grid is not None:\n",
    "        mae_values['grid_search'] = mae_grid\n",
    "    if mae_random is not None:\n",
    "        mae_values['random_search'] = mae_random\n",
    "\n",
    "    if not mae_values:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - 没有有效的 MAE 值，跳过模型选择\")\n",
    "        return None\n",
    "\n",
    "    best_model_type = min(mae_values, key=mae_values.get)\n",
    "    best_mae = mae_values[best_model_type]\n",
    "    print(f\"Ticker {group_df['ticker'].iloc[0]} - 选择的最佳模型: {best_model_type}，测试集 MAE: {best_mae}\")\n",
    "\n",
    "    if best_model_type == 'original':\n",
    "        final_predicted = y_pred_original\n",
    "    elif best_model_type == 'grid_search':\n",
    "        final_predicted = y_pred_grid\n",
    "    else:\n",
    "        final_predicted = y_pred_random\n",
    "\n",
    "    # 构建结果字典\n",
    "    result_dict = {\n",
    "        'ticker': group_df['ticker'].iloc[0],\n",
    "        'selected_features': selected_features,\n",
    "        'original_train_mae': mae_original_train,\n",
    "        'original_train_mape': mape_original_train,\n",
    "        'original_test_mae': mae_original,\n",
    "        'original_test_mape': mape_original,\n",
    "        'grid_train_mae': mae_grid_train if mae_grid_train is not None else np.nan,\n",
    "        'grid_train_mape': mape_grid_train if mape_grid_train is not None else np.nan,\n",
    "        'grid_test_mae': mae_grid if mae_grid is not None else np.nan,\n",
    "        'grid_test_mape': mape_grid if mape_grid is not None else np.nan,\n",
    "        'random_train_mae': mae_random_train if mae_random_train is not None else np.nan,\n",
    "        'random_train_mape': mape_random_train if mape_random_train is not None else np.nan,\n",
    "        'random_test_mae': mae_random if mae_random is not None else np.nan,\n",
    "        'random_test_mape': mape_random if mape_random is not None else np.nan,\n",
    "        'best_model_type': best_model_type,\n",
    "        'best_mae': best_mae,\n",
    "        'original_model': original_model,\n",
    "        'best_model_grid': best_model_grid,\n",
    "        'best_model_random': best_model_random,\n",
    "        'y_test': y_test,\n",
    "        'y_pred_original': y_pred_original,\n",
    "        'y_pred_grid': y_pred_grid if mae_grid is not None else None,\n",
    "        'y_pred_random': y_pred_random if mae_random is not None else None,\n",
    "        'test_dates': test['Date'].values,\n",
    "        'shap_values': shap_values,\n",
    "        'shap_feature_names': X_train_important.columns.tolist(),\n",
    "        'X_train_important': X_train_important,\n",
    "        'best_params_grid': best_params_grid,\n",
    "        'best_params_random': best_params_random,\n",
    "        'cv_results_grid': cv_results_grid,\n",
    "        'cv_results_random': cv_results_random,\n",
    "    }\n",
    "\n",
    "    # 筛选 shap_values 仅包含 selected_features\n",
    "    if shap_values_selected is not None:\n",
    "        try:\n",
    "            # 打印形状信息\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - shap_values_selected.shape: {shap_values_selected.shape}\")\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - X_train_important.shape: {X_train_important.shape}\")\n",
    "\n",
    "            # 确保 shap_values_selected 的样本数与 X_train_important 一致\n",
    "            if shap_values_selected.shape[0] != X_train_important.shape[0]:\n",
    "                print(f\"Ticker {group_df['ticker'].iloc[0]} - shap_values_selected 样本数与 X_train_important 不匹配\")\n",
    "                result_dict['shap_values_selected'] = None\n",
    "            else:\n",
    "                result_dict['shap_values_selected'] = shap_values_selected\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 筛选 shap_values 失败: {str(e)}\")\n",
    "            result_dict['shap_values_selected'] = None\n",
    "    else:\n",
    "        result_dict['shap_values_selected'] = None\n",
    "\n",
    "    # 将最终预测结果保存到结果字典中，包括实际值和最终预测值\n",
    "    predictions = pd.DataFrame({\n",
    "        'Date': test['Date'].values,\n",
    "        'ticker': group_df['ticker'].iloc[0],\n",
    "        'Actual_Return': y_test.values,\n",
    "        'Predicted_Return': final_predicted,\n",
    "        'Best_Model': best_model_type\n",
    "    })\n",
    "    result_dict['predictions'] = predictions\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# 初始化结果列表\n",
    "results = []\n",
    "\n",
    "# 按照 'ticker' 分组\n",
    "grouped = df.groupby('ticker')\n",
    "\n",
    "for name, group in grouped:\n",
    "    print(f\"\\n正在处理 Ticker: {name}\")\n",
    "    result = train_and_predict_single_ticker(\n",
    "        group,\n",
    "        shap_threshold=0.85,          # 您可以更改 shap_threshold 的值\n",
    "        use_feature_selection=False    # 设置为 True，进行特征选择；设置为 False，不进行特征选择\n",
    "    )\n",
    "    if result is not None:\n",
    "        results.append(result)\n",
    "\n",
    "# 将所有预测结果合并\n",
    "if results:\n",
    "    all_predictions = pd.concat([res['predictions'] for res in results], ignore_index=True)\n",
    "\n",
    "    # 确保日期格式正确\n",
    "    all_predictions['Date'] = pd.to_datetime(all_predictions['Date'])\n",
    "\n",
    "    # 保存预测结果为 CSV 文件（可选）\n",
    "    all_predictions.to_csv('predictions.csv', index=False)\n",
    "    print(\"\\n所有预测结果已保存为 'predictions.csv'\")\n",
    "else:\n",
    "    print(\"没有任何预测结果被生成。\")\n",
    "\n",
    "# 绘制 SHAP 图\n",
    "shap.initjs()\n",
    "\n",
    "for res in results:\n",
    "    ticker = res['ticker']\n",
    "    shap_values_selected = res['shap_values_selected']  # 使用筛选后的 shap_values\n",
    "    feature_names = res['shap_feature_names']\n",
    "    X_train_important = res['X_train_important']\n",
    "\n",
    "    print(f\"\\n绘制 Ticker {ticker} 的 SHAP 图\")\n",
    "\n",
    "    # 打印 SHAP 值和数据矩阵的形状\n",
    "    if shap_values_selected is not None:\n",
    "        print(f\"Ticker {ticker} - shap_values_selected.shape: {shap_values_selected.shape}\")\n",
    "        print(f\"Ticker {ticker} - X_train_important.shape: {X_train_important.shape}\")\n",
    "\n",
    "    # 绘制 SHAP summary plot\n",
    "    if shap_values_selected is not None and X_train_important.shape[0] > 0:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_values_selected, X_train_important, feature_names=feature_names, show=False)\n",
    "            plt.title(f\"Ticker {ticker} - SHAP Summary Plot\")\n",
    "            plt.savefig(f'shap_summary_{ticker}.png', dpi=300)\n",
    "            plt.close()\n",
    "            print(f\"保存 Ticker {ticker} 的 SHAP Summary Plot 为 'shap_summary_{ticker}.png'\")\n",
    "\n",
    "            # 绘制 SHAP bar plot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_values_selected, X_train_important, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "            plt.title(f\"Ticker {ticker} - SHAP Feature Importance\")\n",
    "            plt.savefig(f'shap_bar_{ticker}.png', dpi=300)\n",
    "            plt.close()\n",
    "            print(f\"保存 Ticker {ticker} 的 SHAP Feature Importance 图为 'shap_bar_{ticker}.png'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {ticker} 的 SHAP 绘图失败: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"Ticker {ticker} 的 SHAP 值计算失败，无法绘制 SHAP 图\")\n",
    "\n",
    "    # 绘制预测值与真实值的比较图\n",
    "    predictions = res['predictions']\n",
    "    if predictions is not None and not predictions.empty:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(predictions['Date'], predictions['Actual_Return'], label='Actual Return', marker='o')\n",
    "        plt.plot(predictions['Date'], predictions['Predicted_Return'], label='Predicted Return', marker='x')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Return')\n",
    "        plt.title(f'Ticker {ticker} - Actual vs Predicted Returns')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'actual_vs_predicted_{ticker}.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"保存 Ticker {ticker} 的 Actual vs Predicted Returns 图为 'actual_vs_predicted_{ticker}.png'\")\n",
    "    else:\n",
    "        print(f\"Ticker {ticker} 没有足够的数据绘制 Actual vs Predicted Returns 图\")\n",
    "\n",
    "    # 绘制预测误差分布图（可选）\n",
    "    if predictions is not None and not predictions.empty:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        error = predictions['Actual_Return'] - predictions['Predicted_Return']\n",
    "        plt.hist(error, bins=30, edgecolor='k', alpha=0.7)\n",
    "        plt.xlabel('Prediction Error (Actual - Predicted)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(f'Ticker {ticker} - Prediction Error Distribution')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'prediction_error_distribution_{ticker}.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"保存 Ticker {ticker} 的 Prediction Error Distribution 图为 'prediction_error_distribution_{ticker}.png'\")\n",
    "\n",
    "# 输出每个 ticker 的 MAE、MAPE 和最佳模型类型\n",
    "for res in results:\n",
    "    ticker = res['ticker']\n",
    "    print(f\"\\n=== {ticker} 的模型性能 ===\")\n",
    "    print(f\"原始模型训练集 MAE: {res['original_train_mae']}, MAPE: {res['original_train_mape']}%\")\n",
    "    print(f\"原始模型测试集 MAE: {res['original_test_mae']}, MAPE: {res['original_test_mape']}%\")\n",
    "    print(f\"Grid Search 调优模型训练集 MAE: {res['grid_train_mae']}, MAPE: {res['grid_train_mape']}%\")\n",
    "    print(f\"Grid Search 调优模型测试集 MAE: {res['grid_test_mae']}, MAPE: {res['grid_test_mape']}%\")\n",
    "    print(f\"Random Search 调优模型训练集 MAE: {res['random_train_mae']}, MAPE: {res['random_train_mape']}%\")\n",
    "    print(f\"Random Search 调优模型测试集 MAE: {res['random_test_mae']}, MAPE: {res['random_test_mape']}%\")\n",
    "    print(f\"最佳模型类型: {res['best_model_type']}\")\n",
    "    print(f\"最佳模型测试集 MAE: {res['best_mae']}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5734c6-335a-4b2d-926e-9a14b92c642d",
   "metadata": {},
   "source": [
    "預測部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ee9f4-bea8-4b72-ba1e-d64bc8efee57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新的 Jupyter Cell\n",
    "\n",
    "# 假设您已经运行了上面的代码，并且所有的变量都已经定义好\n",
    "\n",
    "# 我们将对每个 ticker 进行逐步预测，每次重新训练模型\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# 初始化一个列表，用于存储所有 ticker 的预测结果\n",
    "all_results = []\n",
    "\n",
    "# 初始化一个列表，用于存储每个 ticker 的平均 MAE 和 MAPE\n",
    "mae_mape_list = []\n",
    "\n",
    "for res in results:\n",
    "    ticker = res['ticker']\n",
    "    print(f\"\\n开始对 Ticker {ticker} 进行逐步预测（每次重新训练模型）\")\n",
    "    \n",
    "    # 获取该 ticker 的数据\n",
    "    group_df = df[df['ticker'] == ticker].sort_values('Date').reset_index(drop=True)\n",
    "    \n",
    "    # 定义特征和目标\n",
    "    target = 'Adj_Close'  # 请确保与之前的代码一致\n",
    "    features = res['selected_features']  # 使用之前选择的特征\n",
    "    \n",
    "    # 初始化用于存储预测结果的列表\n",
    "    dates = []\n",
    "    actuals = []\n",
    "    predictions = []\n",
    "    train_maes = []\n",
    "    train_mapes = []\n",
    "    test_maes = []\n",
    "    test_mapes = []\n",
    "    \n",
    "    # 设置初始训练集大小，例如使用前 80% 的数据作为初始训练集\n",
    "    initial_train_size = int(len(group_df) * 0.8)\n",
    "    train_df = group_df.iloc[:initial_train_size]\n",
    "    test_df = group_df.iloc[initial_train_size:].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Ticker {ticker} 的初始训练集大小: {len(train_df)}, 测试集大小: {len(test_df)}\")\n",
    "    \n",
    "    # 使用之前最好的模型参数（根据最佳模型类型）\n",
    "    best_model_type = res['best_model_type']\n",
    "    if best_model_type == 'original':\n",
    "        params = res['original_model'].get_params()\n",
    "    elif best_model_type == 'grid_search' and res['best_params_grid'] is not None:\n",
    "        params = res['best_params_grid']\n",
    "    elif best_model_type == 'random_search' and res['best_params_random'] is not None:\n",
    "        params = res['best_params_random']\n",
    "    else:\n",
    "        # 如果没有最佳参数，使用默认参数\n",
    "        params = {\n",
    "            'boosting_type': 'dart',\n",
    "            'n_estimators': 100,\n",
    "            'learning_rate': 0.05,\n",
    "            'n_jobs': -1,\n",
    "            'random_state': 7,\n",
    "            'verbose': 0,\n",
    "            'min_data_in_leaf': 5\n",
    "        }\n",
    "    \n",
    "    # 开始逐步预测\n",
    "    for i in range(len(test_df)):\n",
    "        # 当前日期\n",
    "        current_date = test_df['Date'].iloc[i]\n",
    "        \n",
    "        # 当前训练集，包括初始训练集和之前的测试数据\n",
    "        current_train_df = group_df.iloc[:initial_train_size + i]\n",
    "        X_train = current_train_df[features]\n",
    "        y_train = current_train_df[target]\n",
    "        \n",
    "        # 当前测试样本\n",
    "        X_test = test_df[features].iloc[[i]]  # 注意这里要保持二维数组\n",
    "        y_test = test_df[target].iloc[[i]]    # 保持 Series 格式\n",
    "        \n",
    "        # 训练模型（重新训练）\n",
    "        model = lgb.LGBMRegressor(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        \n",
    "        # 预测\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # 计算训练集 MAE 和 MAPE\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "        train_mape = mean_absolute_percentage_error(y_train, y_train_pred) * 100  # 转换为百分比\n",
    "        \n",
    "        # 计算测试集（单个样本）MAE 和 MAPE\n",
    "        test_mae = mean_absolute_error(y_test, y_pred)\n",
    "        test_mape = mean_absolute_percentage_error(y_test, y_pred) * 100  # 转换为百分比\n",
    "        \n",
    "        # 保存结果\n",
    "        dates.append(current_date)\n",
    "        actuals.append(y_test.values[0])\n",
    "        predictions.append(y_pred[0])  # y_pred 是数组\n",
    "        train_maes.append(train_mae)\n",
    "        train_mapes.append(train_mape)\n",
    "        test_maes.append(test_mae)\n",
    "        test_mapes.append(test_mape)\n",
    "        \n",
    "        # 可选：打印当前进度\n",
    "        print(f\"日期: {current_date.date()}, 实际值: {y_test.values[0]}, 预测值: {y_pred[0]}, 训练 MAE: {train_mae:.4f}, 训练 MAPE: {train_mape:.2f}%, 测试 MAE: {test_mae:.4f}, 测试 MAPE: {test_mape:.2f}%\")\n",
    "    \n",
    "    # 将结果转换为 DataFrame\n",
    "    results_df = pd.DataFrame({\n",
    "        'Date': dates,\n",
    "        'Actual': actuals,\n",
    "        'Predicted': predictions,\n",
    "        'Train_MAE': train_maes,\n",
    "        'Train_MAPE': train_mapes,\n",
    "        'Test_MAE': test_maes,\n",
    "        'Test_MAPE': test_mapes\n",
    "    })\n",
    "    \n",
    "    # 添加 'Ticker' 列\n",
    "    results_df['Ticker'] = ticker\n",
    "    \n",
    "    # 将结果添加到所有结果的列表中\n",
    "    all_results.append(results_df)\n",
    "    \n",
    "    # 计算该 ticker 的平均训练和测试 MAE、MAPE\n",
    "    avg_train_mae = np.mean(train_maes)\n",
    "    avg_train_mape = np.mean(train_mapes)\n",
    "    avg_test_mae = np.mean(test_maes)\n",
    "    avg_test_mape = np.mean(test_mapes)\n",
    "    \n",
    "    # 将平均 MAE 和 MAPE 添加到列表中\n",
    "    mae_mape_list.append({\n",
    "        'Ticker': ticker,\n",
    "        'Avg_Train_MAE': avg_train_mae,\n",
    "        'Avg_Train_MAPE': avg_train_mape,\n",
    "        'Avg_Test_MAE': avg_test_mae,\n",
    "        'Avg_Test_MAPE': avg_test_mape\n",
    "    })\n",
    "    \n",
    "    # 绘制实际值和预测值的对比图\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results_df['Date'], results_df['Actual'], label='Actual', marker='o')\n",
    "    plt.plot(results_df['Date'], results_df['Predicted'], label='Predicted', marker='x')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel(target)\n",
    "    plt.title(f'Ticker {ticker} - 逐步预测结果（每次重新训练模型）')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'step_by_step_prediction_{ticker}.png', dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"保存 Ticker {ticker} 的逐步预测图为 'step_by_step_prediction_{ticker}.png'\")\n",
    "    \n",
    "    # 绘制训练集 MAE 和 测试集 MAE 的变化趋势\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results_df['Date'], results_df['Train_MAE'], label='Train MAE', marker='o')\n",
    "    plt.plot(results_df['Date'], results_df['Test_MAE'], label='Test MAE', marker='x')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('MAE')\n",
    "    plt.title(f'Ticker {ticker} - MAE 随时间的变化')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'mae_over_time_{ticker}.png', dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"保存 Ticker {ticker} 的 MAE 变化图为 'mae_over_time_{ticker}.png'\")\n",
    "    \n",
    "    # 绘制训练集 MAPE 和 测试集 MAPE 的变化趋势\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(results_df['Date'], results_df['Train_MAPE'], label='Train MAPE', marker='o')\n",
    "    plt.plot(results_df['Date'], results_df['Test_MAPE'], label='Test MAPE', marker='x')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('MAPE (%)')\n",
    "    plt.title(f'Ticker {ticker} - MAPE 随时间的变化')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'mape_over_time_{ticker}.png', dpi=300)\n",
    "    plt.show()\n",
    "    print(f\"保存 Ticker {ticker} 的 MAPE 变化图为 'mape_over_time_{ticker}.png'\")\n",
    "\n",
    "# 在循环结束后，合并所有的预测结果\n",
    "if all_results:\n",
    "    consolidated_results = pd.concat(all_results, ignore_index=True)\n",
    "    \n",
    "    # 保存所有预测结果到 CSV 文件\n",
    "    consolidated_results.to_csv('consolidated_predictions.csv', index=False)\n",
    "    print(\"所有 ticker 的预测结果已保存到 'consolidated_predictions.csv'\")\n",
    "else:\n",
    "    print(\"没有任何预测结果生成。\")\n",
    "\n",
    "# 将平均 MAE 和 MAPE 保存到 CSV 文件\n",
    "mae_mape_df = pd.DataFrame(mae_mape_list)\n",
    "mae_mape_df.to_csv('ticker_mae_mape.csv', index=False)\n",
    "print(\"所有 ticker 的平均 MAE 和 MAPE 已保存到 'ticker_mae_mape.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55bbca52-2147-4661-885e-1e1e2793581e",
   "metadata": {},
   "source": [
    "投組部分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deddca19-b36c-4532-b165-a4555df54126",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import empyrical as ep\n",
    "from pypfopt import EfficientFrontier, expected_returns, risk_models\n",
    "\n",
    "# 1. 读取股票价格数据\n",
    "df_prices = pd.read_csv('股價.csv')\n",
    "\n",
    "# 转换 'Date' 为日期类型\n",
    "df_prices['Date'] = pd.to_datetime(df_prices['Date'])\n",
    "\n",
    "# 数据透视，将 'ticker' 作为列，将 'Adj_Close' 作为值\n",
    "df_prices = df_prices.pivot(index='Date', columns='ticker', values='Adj_Close')\n",
    "\n",
    "# 数据清洗\n",
    "df_prices.dropna(how='all', inplace=True)\n",
    "df_prices = df_prices.apply(lambda x: pd.to_numeric(x.astype(str).str.replace(',', ''), errors='coerce'))\n",
    "df_prices[df_prices <= 0] = np.nan\n",
    "\n",
    "# 填充缺失值\n",
    "df_prices.fillna(method='ffill', inplace=True)\n",
    "df_prices.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# 将列名转换为字符串类型\n",
    "df_prices.columns = df_prices.columns.astype(str)\n",
    "\n",
    "# 2. 读取预测数据\n",
    "all_predictions = pd.read_csv('predictions.csv')\n",
    "\n",
    "# 转换数据类型\n",
    "all_predictions['Date'] = pd.to_datetime(all_predictions['Date'])\n",
    "all_predictions['ticker'] = all_predictions['ticker'].astype(str)\n",
    "all_predictions['Predicted_Return'] = pd.to_numeric(all_predictions['Predicted_Return'], errors='coerce')\n",
    "\n",
    "# 按照日期和股票代码排序\n",
    "all_predictions.sort_values(by=['ticker', 'Date'], inplace=True)\n",
    "\n",
    "# 去除缺失的预测回报率\n",
    "all_predictions.dropna(subset=['Predicted_Return'], inplace=True)\n",
    "\n",
    "# 获取预测数据中的最早日期\n",
    "start_date = all_predictions['Date'].min()\n",
    "end_date = df_prices.index.max()\n",
    "\n",
    "# 确保价格数据包含预测数据的日期范围\n",
    "df_prices = df_prices.loc[start_date:]\n",
    "\n",
    "# 按周汇总预测回报率（取平均值）\n",
    "all_predictions['Week_Start'] = all_predictions['Date'] - pd.to_timedelta(all_predictions['Date'].dt.weekday, unit='d')\n",
    "weekly_predictions = all_predictions.groupby(['Week_Start', 'ticker'])['Predicted_Return'].mean().reset_index()\n",
    "\n",
    "# 设置投资组合初始资金\n",
    "initial_portfolio_value = 100000000\n",
    "cash = initial_portfolio_value\n",
    "\n",
    "# 初始化持仓和投资组合价值记录\n",
    "current_allocation = {}\n",
    "portfolio_value_per_day = pd.DataFrame(index=df_prices.index)\n",
    "portfolio_value_per_day['Total'] = np.nan\n",
    "\n",
    "# 记录每次调整的权重和交易信息\n",
    "trade_history = []\n",
    "\n",
    "# 获取预测数据中所有周的列表\n",
    "weeks = pd.date_range(start=start_date, end=end_date, freq='W-MON')\n",
    "\n",
    "# 定义辅助函数\n",
    "def get_next_trading_day(target_date, price_index):\n",
    "    \"\"\"\n",
    "    如果 target_date 存在于 price_index 中，返回 target_date。\n",
    "    否则，返回第一个在 target_date 之后存在于 price_index 中的日期。\n",
    "    如果找不到，返回 None。\n",
    "    \"\"\"\n",
    "    if target_date in price_index:\n",
    "        return target_date\n",
    "    else:\n",
    "        # 查找所有大于 target_date 的日期\n",
    "        future_dates = price_index[price_index > target_date]\n",
    "        if not future_dates.empty:\n",
    "            return future_dates.min()\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "def get_top_20_stocks_weekly(predictions_df, date):\n",
    "    # 获取指定周的预测结果\n",
    "    predictions_on_week = predictions_df[predictions_df['Week_Start'] == date]\n",
    "    \n",
    "    # 如果没有预测结果，返回空列表\n",
    "    if predictions_on_week.empty:\n",
    "        return [], predictions_on_week\n",
    "    \n",
    "    # 按照预测回报率排序，选出前20只股票\n",
    "    top_20 = predictions_on_week.sort_values(by='Predicted_Return', ascending=False).head(20)\n",
    "    \n",
    "    # 将股票代码转换为字符串\n",
    "    top_20['ticker'] = top_20['ticker'].astype(str)\n",
    "    \n",
    "    return top_20['ticker'].tolist(), top_20\n",
    "\n",
    "def adjust_portfolio(top_stocks, valid_prices, current_allocation, cash, predictions_on_date, rebalance_date):\n",
    "    # 获取历史价格数据\n",
    "    historical_data = df_prices[top_stocks].loc[:rebalance_date].dropna()\n",
    "    \n",
    "    # 如果历史数据不足，使用默认的等权重\n",
    "    if historical_data.shape[0] < 2:\n",
    "        weights = {stock: 1/len(top_stocks) for stock in top_stocks}\n",
    "    else:\n",
    "        # 使用 PyPortfolioOpt 计算预期收益率和协方差矩阵\n",
    "        mu = expected_returns.mean_historical_return(historical_data)\n",
    "        S = risk_models.CovarianceShrinkage(historical_data).ledoit_wolf()\n",
    "        \n",
    "        try:\n",
    "            # 构建有效前沿模型，计算最大夏普比率的权重\n",
    "            ef = EfficientFrontier(mu, S, weight_bounds=(0, 1))\n",
    "            raw_weights = ef.max_sharpe()\n",
    "            cleaned_weights = ef.clean_weights()\n",
    "            weights = cleaned_weights\n",
    "        except Exception as e:\n",
    "            print(f\"优化时出错，使用等权重：{e}\")\n",
    "            weights = {stock: 1/len(top_stocks) for stock in top_stocks}\n",
    "    \n",
    "    # 确保权重的股票代码为字符串类型\n",
    "    weights = {str(k): v for k, v in weights.items()}\n",
    "    \n",
    "    # 记录当前的交易信息\n",
    "    trade_info = {\n",
    "        'Date': rebalance_date,\n",
    "        'Buy': [],\n",
    "        'Sell': [],\n",
    "        'Weights': weights\n",
    "    }\n",
    "    \n",
    "    # 计算当前投资组合总价值\n",
    "    total_portfolio_value = sum(current_allocation.get(stock, 0) * valid_prices.get(stock, 0) for stock in current_allocation) + cash\n",
    "    \n",
    "    # 计算目标持仓\n",
    "    valid_prices = {k: float(v) for k, v in valid_prices.items() if pd.notna(v) and isinstance(v, (int, float))}\n",
    "    target_allocations = {stock: weights.get(stock, 0) * total_portfolio_value for stock in top_stocks if stock in valid_prices}\n",
    "    target_shares = {stock: target_allocations[stock] / valid_prices[stock] for stock in target_allocations}\n",
    "    \n",
    "    # **先卖出需要卖出的股票**\n",
    "    # 卖出未在新持仓中的股票\n",
    "    for stock in list(current_allocation.keys()):\n",
    "        if stock not in top_stocks:\n",
    "            shares_to_sell = current_allocation[stock]\n",
    "            price = valid_prices.get(stock, df_prices.loc[rebalance_date, stock])\n",
    "            if pd.notna(price) and isinstance(price, (int, float)):\n",
    "                proceeds = shares_to_sell * price\n",
    "                fee = proceeds * 0.004425  # 卖出手续费 0.4425%\n",
    "                cash += proceeds - fee\n",
    "                print(f\"卖出 {stock} 的 {shares_to_sell:.2f} 股，获得现金 {proceeds - fee:.2f}，手续费 {fee:.2f}\")\n",
    "                trade_info['Sell'].append({'Stock': stock, 'Shares': shares_to_sell, 'Proceeds': proceeds - fee, 'Fee': fee})\n",
    "                del current_allocation[stock]\n",
    "    \n",
    "    # 卖出需要减少的股票\n",
    "    for stock in top_stocks:\n",
    "        if stock in current_allocation:\n",
    "            target_shares_to_hold = target_shares.get(stock, 0)\n",
    "            current_shares = current_allocation.get(stock, 0)\n",
    "            price = valid_prices.get(stock, 0)\n",
    "            if current_shares > target_shares_to_hold:\n",
    "                # 卖出多余的部分\n",
    "                shares_to_sell = current_shares - target_shares_to_hold\n",
    "                proceeds = shares_to_sell * price\n",
    "                fee = proceeds * 0.004425  # 卖出手续费 0.4425%\n",
    "                cash += proceeds - fee\n",
    "                current_allocation[stock] = target_shares_to_hold\n",
    "                print(f\"卖出 {stock} 的 {shares_to_sell:.2f} 股，获得现金 {proceeds - fee:.2f}，手续费 {fee:.2f}\")\n",
    "                trade_info['Sell'].append({'Stock': stock, 'Shares': shares_to_sell, 'Proceeds': proceeds - fee, 'Fee': fee})\n",
    "    \n",
    "    # **然后买入需要买入的股票**\n",
    "    for stock in top_stocks:\n",
    "        target_shares_to_hold = target_shares.get(stock, 0)\n",
    "        current_shares = current_allocation.get(stock, 0)\n",
    "        price = valid_prices.get(stock, 0)\n",
    "        if current_shares < target_shares_to_hold:\n",
    "            # 买入缺少的部分\n",
    "            shares_to_buy = target_shares_to_hold - current_shares\n",
    "            cost = shares_to_buy * price\n",
    "            fee = cost * 0.001425  # 买入手续费 0.1425%\n",
    "            total_cost = cost + fee\n",
    "            if total_cost <= cash:\n",
    "                cash -= total_cost\n",
    "                current_allocation[stock] = target_shares_to_hold\n",
    "                print(f\"买入 {stock} 的 {shares_to_buy:.2f} 股，花费现金 {total_cost:.2f}，手续费 {fee:.2f}\")\n",
    "                trade_info['Buy'].append({'Stock': stock, 'Shares': shares_to_buy, 'Cost': total_cost, 'Fee': fee})\n",
    "            else:\n",
    "                # 现金不足，按比例购买\n",
    "                affordable_shares = (cash / (price + price * 0.001425))\n",
    "                shares_to_buy = affordable_shares\n",
    "                cost = shares_to_buy * price\n",
    "                fee = cost * 0.001425\n",
    "                total_cost = cost + fee\n",
    "                cash -= total_cost\n",
    "                current_allocation[stock] = current_shares + shares_to_buy\n",
    "                print(f\"现金不足，调整 {stock} 的买入数量为 {shares_to_buy:.2f} 股，花费现金 {total_cost:.2f}，手续费 {fee:.2f}\")\n",
    "                trade_info['Buy'].append({'Stock': stock, 'Shares': shares_to_buy, 'Cost': total_cost, 'Fee': fee})\n",
    "    \n",
    "    # 记录交易信息\n",
    "    trade_history.append(trade_info)\n",
    "    \n",
    "    return current_allocation, cash\n",
    "\n",
    "# 主循环\n",
    "for week_start in weeks:\n",
    "    print(f\"\\n处理周开始日期：{week_start.strftime('%Y-%m-%d')}\")\n",
    "    week_end = week_start + pd.Timedelta(days=6)  # 一周的结束日期\n",
    "    \n",
    "    # 获取本周的开始日期\n",
    "    rebalance_date = week_start\n",
    "    \n",
    "    # 检查 rebalance_date 是否存在于 df_prices.index 中\n",
    "    actual_rebalance_date = get_next_trading_day(rebalance_date, df_prices.index)\n",
    "    if actual_rebalance_date is None:\n",
    "        print(f\"{rebalance_date.strftime('%Y-%m-%d')} 之后没有可用的交易日，跳过该周。\")\n",
    "        continue\n",
    "    elif actual_rebalance_date != rebalance_date:\n",
    "        print(f\"原始 rebalance_date {rebalance_date.strftime('%Y-%m-%d')} 不存在，使用下一个交易日 {actual_rebalance_date.strftime('%Y-%m-%d')}。\")\n",
    "        rebalance_date = actual_rebalance_date\n",
    "    \n",
    "    # 获取预测回报率最高的20只股票\n",
    "    top_stocks, predictions_on_date = get_top_20_stocks_weekly(weekly_predictions, rebalance_date)\n",
    "    if not top_stocks:\n",
    "        print(f\"{rebalance_date.strftime('%Y-%m-%d')} 没有可用的预测结果，跳过该周。\")\n",
    "        continue\n",
    "    \n",
    "    # 确保 df_prices 的列名是字符串类型\n",
    "    df_prices.columns = df_prices.columns.astype(str)\n",
    "    # 将 top_stocks 中的股票代码转换为字符串\n",
    "    top_stocks = [str(stock) for stock in top_stocks]\n",
    "    \n",
    "    # 获取本周第一个交易日的价格\n",
    "    try:\n",
    "        week_prices = df_prices.loc[rebalance_date:week_end, top_stocks]\n",
    "        earliest_prices = week_prices.iloc[0]\n",
    "    except IndexError:\n",
    "        print(f\"{rebalance_date.strftime('%Y-%m-%d')} 没有足够的交易日，跳过该周。\")\n",
    "        continue\n",
    "    except KeyError as e:\n",
    "        print(f\"{rebalance_date.strftime('%Y-%m-%d')} 发生 KeyError：{e}\")\n",
    "        continue\n",
    "    \n",
    "    earliest_prices = earliest_prices.dropna()\n",
    "    valid_prices = earliest_prices.to_dict()\n",
    "    \n",
    "    # 过滤掉没有价格数据的股票\n",
    "    top_stocks = [stock for stock in top_stocks if stock in valid_prices]\n",
    "    predictions_on_date = predictions_on_date[predictions_on_date['ticker'].isin(top_stocks)]\n",
    "    \n",
    "    if not top_stocks:\n",
    "        print(f\"{rebalance_date.strftime('%Y-%m-%d')} 无有效的股票可交易，跳过该周。\")\n",
    "        continue\n",
    "    \n",
    "    # 调整投资组合\n",
    "    current_allocation, cash = adjust_portfolio(top_stocks, valid_prices, current_allocation, cash, predictions_on_date, rebalance_date)\n",
    "    \n",
    "    # 计算每日投资组合市值\n",
    "    held_stocks = list(current_allocation.keys())\n",
    "    if held_stocks:\n",
    "        try:\n",
    "            week_prices = df_prices.loc[rebalance_date:week_end, held_stocks]\n",
    "            holdings = pd.Series(current_allocation)\n",
    "            daily_portfolio_value = (week_prices * holdings).sum(axis=1) + cash\n",
    "            portfolio_value_per_day.loc[rebalance_date:week_end, 'Total'] = daily_portfolio_value\n",
    "        except Exception as e:\n",
    "            print(f\"{rebalance_date.strftime('%Y-%m-%d')}: 计算每日市值时出错: {e}\")\n",
    "\n",
    "# 填充缺失的投资组合市值\n",
    "portfolio_value_per_day['Total'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# 计算投资组合的每日收益率和累计收益率\n",
    "daily_returns = portfolio_value_per_day['Total'].pct_change().dropna()\n",
    "portfolio_value_per_day['Cumulative Returns'] = (1 + daily_returns).cumprod() - 1\n",
    "\n",
    "# 使用 empyrical 计算投资组合的绩效指标\n",
    "annual_return = ep.annual_return(daily_returns)\n",
    "sharpe_ratio = ep.sharpe_ratio(daily_returns)\n",
    "max_drawdown = ep.max_drawdown(daily_returns)\n",
    "\n",
    "print(\"\\n=== 投资组合绩效指标 ===\")\n",
    "print(f\"年化收益率: {annual_return:.2%}\")\n",
    "print(f\"夏普比率: {sharpe_ratio:.2f}\")\n",
    "print(f\"最大回撤: {max_drawdown:.2%}\")\n",
    "\n",
    "# 读取加权指数数据\n",
    "index_prices = pd.read_csv('TWII.csv')\n",
    "index_prices['Date'] = pd.to_datetime(index_prices['Date'])\n",
    "index_prices.set_index('Date', inplace=True)\n",
    "index_prices.sort_index(inplace=True)\n",
    "\n",
    "# 确保加权指数数据起始日期正确\n",
    "index_prices = index_prices[index_prices.index >= start_date]\n",
    "\n",
    "# 将 'Close' 列的字符串转换为浮点数\n",
    "index_prices['Close'] = index_prices['Close'].astype(str).str.replace(',', '').astype(float)\n",
    "\n",
    "# 对齐指数数据和投资组合数据的日期范围\n",
    "common_dates = portfolio_value_per_day.index.intersection(index_prices.index)\n",
    "index_prices = index_prices.loc[common_dates]\n",
    "portfolio_value_per_day = portfolio_value_per_day.loc[common_dates]\n",
    "\n",
    "# 计算加权指数的每日收益率和累计收益率\n",
    "index_prices['Index Returns'] = index_prices['Close'].pct_change()\n",
    "index_prices['Index Cumulative Returns'] = (1 + index_prices['Index Returns']).cumprod() - 1\n",
    "\n",
    "# 计算加权指数的绩效指标\n",
    "index_daily_returns = index_prices['Index Returns'].dropna()\n",
    "index_annual_return = ep.annual_return(index_daily_returns)\n",
    "index_sharpe_ratio = ep.sharpe_ratio(index_daily_returns)\n",
    "index_max_drawdown = ep.max_drawdown(index_daily_returns)\n",
    "\n",
    "print(\"\\n=== 加权指数绩效指标 ===\")\n",
    "print(f\"年化收益率: {index_annual_return:.2%}\")\n",
    "print(f\"夏普比率: {index_sharpe_ratio:.2f}\")\n",
    "print(f\"最大回撤: {index_max_drawdown:.2%}\")\n",
    "\n",
    "# 绘制投资组合和加权指数的累计收益率比较图\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(portfolio_value_per_day.index, portfolio_value_per_day['Cumulative Returns'], label='投资组合累计收益率', color='blue')\n",
    "plt.plot(index_prices.index, index_prices['Index Cumulative Returns'], label='加权指数累计收益率', color='red')\n",
    "plt.title('投资组合与加权指数累计收益率比较')\n",
    "plt.xlabel('日期')\n",
    "plt.ylabel('累计收益率')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 保存交易历史到 CSV 文件\n",
    "trade_history_df = pd.DataFrame(trade_history)\n",
    "trade_history_df.to_csv('trade_history.csv', index=False)\n",
    "print(\"交易历史已保存到 'trade_history.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2869f6c5-d262-460f-8b76-e55a9bcb806a",
   "metadata": {},
   "source": [
    "GPU部分(不確定)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773a2512-1cb4-4dd7-9f77-b54307ccb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV, RandomizedSearchCV\n",
    "import lightgbm as lgb\n",
    "import shap\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import timedelta\n",
    "\n",
    "# 忽略警告\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置 matplotlib 字体以显示中文\n",
    "plt.rcParams['font.sans-serif'] = ['Microsoft YaHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# ---------------------------\n",
    "# 模型预测部分\n",
    "# ---------------------------\n",
    "\n",
    "class LightGBMModel:\n",
    "    @staticmethod\n",
    "    def shap_feature_importance(train_X, train_Y, params, isClassifier=True):\n",
    "        \"\"\"\n",
    "        使用 SHAP 计算特征重要性\n",
    "\n",
    "        :param train_X: 训练集特征\n",
    "        :param train_Y: 训练集标签\n",
    "        :param params: 模型参数\n",
    "        :param isClassifier: 是否为分类模型\n",
    "        :return: 特征重要性数据框、SHAP 值和模型\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isClassifier:\n",
    "                model = lgb.LGBMClassifier(**params, device='gpu')\n",
    "            else:\n",
    "                model = lgb.LGBMRegressor(**params, device='gpu')\n",
    "\n",
    "            model.fit(train_X, train_Y)\n",
    "            explainer = shap.TreeExplainer(model)\n",
    "            shap_values = explainer.shap_values(train_X)\n",
    "\n",
    "            # 计算特征重要性\n",
    "            mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "            feature_importance_df = pd.DataFrame({'Feature': train_X.columns, 'Importance': mean_abs_shap})\n",
    "            feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "            return feature_importance_df, shap_values, model\n",
    "        except Exception as e:\n",
    "            print('shap_feature_importance has error: ' + str(e))\n",
    "            return None, None, None\n",
    "\n",
    "    @staticmethod\n",
    "    def grid_tune(train_X, train_Y, fold_time, param_grid, isClassifier=True):\n",
    "        \"\"\"\n",
    "        使用网格搜索进行参数调优\n",
    "\n",
    "        :param train_X: 训练集特征\n",
    "        :param train_Y: 训练集标签\n",
    "        :param fold_time: 交叉验证次数\n",
    "        :param param_grid: 参数网格\n",
    "        :param isClassifier: 是否为分类模型\n",
    "        :return: 最佳模型、最佳参数和交叉验证结果\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isClassifier:\n",
    "                model = lgb.LGBMClassifier(device='gpu')\n",
    "                scoring = 'accuracy'\n",
    "            else:\n",
    "                model = lgb.LGBMRegressor(device='gpu')\n",
    "                scoring = 'neg_mean_absolute_error'\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=fold_time)\n",
    "\n",
    "            grid_search = GridSearchCV(\n",
    "                estimator=model,\n",
    "                param_grid=param_grid,\n",
    "                cv=tscv,\n",
    "                n_jobs=-1,\n",
    "                scoring=scoring,\n",
    "                verbose=1\n",
    "            )\n",
    "            grid_search.fit(train_X, train_Y)\n",
    "            best_model = grid_search.best_estimator_\n",
    "            best_params = grid_search.best_params_\n",
    "            cv_results = pd.DataFrame(grid_search.cv_results_)\n",
    "            return best_model, best_params, cv_results\n",
    "        except Exception as e:\n",
    "            print('grid_tune has error: ' + str(e))\n",
    "            return None, None, None\n",
    "\n",
    "    @staticmethod\n",
    "    def random_tune(train_X, train_Y, fold_time, param_distributions, isClassifier=True, n_iter=10):\n",
    "        \"\"\"\n",
    "        使用随机搜索进行参数调优\n",
    "\n",
    "        :param train_X: 训练集特征\n",
    "        :param train_Y: 训练集标签\n",
    "        :param fold_time: 交叉验证次数\n",
    "        :param param_distributions: 参数分布\n",
    "        :param isClassifier: 是否为分类模型\n",
    "        :param n_iter: 随机搜索迭代次数\n",
    "        :return: 最佳模型、最佳参数和交叉验证结果\n",
    "        \"\"\"\n",
    "        try:\n",
    "            if isClassifier:\n",
    "                model = lgb.LGBMClassifier(device='gpu')\n",
    "                scoring = 'accuracy'\n",
    "            else:\n",
    "                model = lgb.LGBMRegressor(device='gpu')\n",
    "                scoring = 'neg_mean_absolute_error'\n",
    "\n",
    "            tscv = TimeSeriesSplit(n_splits=fold_time)\n",
    "\n",
    "            random_search = RandomizedSearchCV(\n",
    "                estimator=model,\n",
    "                param_distributions=param_distributions,\n",
    "                cv=tscv,\n",
    "                n_jobs=-1,\n",
    "                scoring=scoring,\n",
    "                n_iter=n_iter,\n",
    "                verbose=1,\n",
    "                random_state=42\n",
    "            )\n",
    "            random_search.fit(train_X, train_Y)\n",
    "            best_model = random_search.best_estimator_\n",
    "            best_params = random_search.best_params_\n",
    "            cv_results = pd.DataFrame(random_search.cv_results_)\n",
    "            return best_model, best_params, cv_results\n",
    "        except Exception as e:\n",
    "            print('random_tune has error: ' + str(e))\n",
    "            return None, None, None\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('完整的合併資料.csv')\n",
    "\n",
    "# 将 'Date' 列转换为 datetime 类型\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# 确保数据按照 'ticker' 和 'Date' 排序\n",
    "df = df.sort_values(['ticker', 'Date']).reset_index(drop=True)\n",
    "\n",
    "# 定义目标变量和特征\n",
    "target = 'Adj_Close'  # 请替换为您的目标变量名称\n",
    "features = [col for col in df.columns if col not in ['Date', 'ticker', target]]\n",
    "\n",
    "def train_and_predict_single_ticker(group_df, shap_threshold=0.85, use_feature_selection=True):\n",
    "    # 确保数据按照日期排序\n",
    "    group_df = group_df.sort_values('Date').reset_index(drop=True)\n",
    "\n",
    "    # 如果数据量太少，无法训练，则跳过\n",
    "    if len(group_df) < 20:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} 数据量不足，跳过\")\n",
    "        return None\n",
    "\n",
    "    # 使用前 80% 的数据作为训练集，后 20% 的数据作为测试集\n",
    "    split_index = int(len(group_df) * 0.8)\n",
    "    train = group_df.iloc[:split_index]\n",
    "    test = group_df.iloc[split_index:]\n",
    "\n",
    "    if len(test) == 0:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} 测试集为空，跳过\")\n",
    "        return None\n",
    "\n",
    "    X_train = train[features]\n",
    "    y_train = train[target]\n",
    "    X_test = test[features]\n",
    "    y_test = test[target]\n",
    "\n",
    "    # 模型参数（原始模型）\n",
    "    params = {\n",
    "        'boosting_type': 'dart',\n",
    "        'n_estimators': 100,\n",
    "        'learning_rate': 0.05,\n",
    "        'n_jobs': -1,\n",
    "        'random_state': 7,\n",
    "        'verbose': 0,\n",
    "        'min_data_in_leaf': 5,\n",
    "    }\n",
    "\n",
    "    # 1. 计算 SHAP 值（无论是否进行特征选择）\n",
    "    try:\n",
    "        feature_importance_df, shap_values, initial_model = LightGBMModel.shap_feature_importance(\n",
    "            X_train, y_train, params=params, isClassifier=False)\n",
    "        if feature_importance_df is not None:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - SHAP 计算成功\")\n",
    "        else:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - SHAP 计算失败\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - SHAP 计算异常: {str(e)}\")\n",
    "        feature_importance_df, shap_values, initial_model = None, None, None\n",
    "\n",
    "    if use_feature_selection and feature_importance_df is not None:\n",
    "        try:\n",
    "            # 计算累计贡献度\n",
    "            total_importance = feature_importance_df['Importance'].sum()\n",
    "            feature_importance_df['Cumulative'] = feature_importance_df['Importance'].cumsum() / total_importance\n",
    "            # 根据阈值选择特征\n",
    "            important_features = feature_importance_df[feature_importance_df['Cumulative'] <= shap_threshold]['Feature'].tolist()\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 选择的特征数量：{len(important_features)}\")\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 选择的特征：{important_features}\")\n",
    "            selected_features = important_features\n",
    "            # 筛选 shap_values\n",
    "            selected_feature_indices = [X_train.columns.get_loc(f) for f in selected_features]\n",
    "            shap_values_selected = shap_values[:, selected_feature_indices]\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 特征筛选失败: {str(e)}\")\n",
    "            selected_features = features.copy()\n",
    "            shap_values_selected = shap_values\n",
    "    else:\n",
    "        # 不进行特征选择，使用所有特征\n",
    "        selected_features = features.copy()\n",
    "        shap_values_selected = shap_values\n",
    "        if not use_feature_selection:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 未进行特征选择，使用所有特征\")\n",
    "\n",
    "    # 使用重要特征进行模型训练（原始模型）\n",
    "    X_train_important = X_train[selected_features]\n",
    "    X_test_important = X_test[selected_features]\n",
    "\n",
    "    # 1. 训练原始模型\n",
    "    try:\n",
    "        original_model = lgb.LGBMRegressor(**params, device='gpu')\n",
    "        original_model.fit(X_train_important, y_train)\n",
    "        y_pred_original = original_model.predict(X_test_important)\n",
    "        mae_original = mean_absolute_error(y_test, y_pred_original)\n",
    "        mape_original = mean_absolute_percentage_error(y_test, y_pred_original) * 100  # 转换为百分比\n",
    "        mae_original_train = mean_absolute_error(y_train, original_model.predict(X_train_important))\n",
    "        mape_original_train = mean_absolute_percentage_error(y_train, original_model.predict(X_train_important)) * 100  # 转换为百分比\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - 原始模型训练集 MAE: {mae_original_train}, MAPE: {mape_original_train}%\")\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - 原始模型测试集 MAE: {mae_original}, MAPE: {mape_original}%\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - 原始模型训练失败: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "    # 2. 参数调优 - 网格搜索\n",
    "    param_grid = {\n",
    "        'learning_rate': [0.005, 0.01, 0.03, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 9, -1],\n",
    "        'num_leaves': [31, 63],\n",
    "        'n_estimators': [100, 200],\n",
    "        'boosting_type': ['gbdt', 'dart'],\n",
    "        'random_state': [7],\n",
    "    }\n",
    "\n",
    "    best_model_grid, best_params_grid, cv_results_grid = LightGBMModel.grid_tune(\n",
    "        X_train_important, y_train, fold_time=5, param_grid=param_grid, isClassifier=False)\n",
    "\n",
    "    if best_model_grid is not None:\n",
    "        try:\n",
    "            y_pred_grid = best_model_grid.predict(X_test_important)\n",
    "            mae_grid = mean_absolute_error(y_test, y_pred_grid)\n",
    "            mape_grid = mean_absolute_percentage_error(y_test, y_pred_grid) * 100  # 转换为百分比\n",
    "            mae_grid_train = mean_absolute_error(y_train, best_model_grid.predict(X_train_important))\n",
    "            mape_grid_train = mean_absolute_percentage_error(y_train, best_model_grid.predict(X_train_important)) * 100  # 转换为百分比\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Grid Search 训练集 MAE: {mae_grid_train}, MAPE: {mape_grid_train}%\")\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Grid Search 测试集 MAE: {mae_grid}, MAPE: {mape_grid}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Grid Search 预测失败: {str(e)}\")\n",
    "            mae_grid, mape_grid, mae_grid_train, mape_grid_train = None, None, None, None\n",
    "    else:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - Grid Search 未找到最佳模型，使用原始模型的预测结果。\")\n",
    "        best_model_grid = original_model\n",
    "        y_pred_grid = y_pred_original\n",
    "        mae_grid = mae_original\n",
    "        mape_grid = mape_original\n",
    "        mae_grid_train = mae_original_train\n",
    "        mape_grid_train = mape_original_train\n",
    "\n",
    "    # 3. 参数调优 - 随机搜索\n",
    "    param_dist = {\n",
    "        'learning_rate': [0.005, 0.01, 0.05, 0.1],\n",
    "        'max_depth': [3, 5, 7, 9, -1],\n",
    "        'num_leaves': [15, 31, 63, 127],\n",
    "        'n_estimators': [50, 100, 200, 500],\n",
    "        'min_child_samples': [5, 10, 20, 50],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'lambda_l1': [0, 0.01, 0.1, 1],\n",
    "        'lambda_l2': [0, 0.01, 0.1, 1],\n",
    "        'boosting_type': ['gbdt', 'dart'],\n",
    "        'random_state': [7],\n",
    "    }\n",
    "\n",
    "    best_model_random, best_params_random, cv_results_random = LightGBMModel.random_tune(\n",
    "        X_train_important, y_train, fold_time=5, param_distributions=param_dist, isClassifier=False, n_iter=100)\n",
    "\n",
    "    if best_model_random is not None:\n",
    "        try:\n",
    "            y_pred_random = best_model_random.predict(X_test_important)\n",
    "            mae_random = mean_absolute_error(y_test, y_pred_random)\n",
    "            mape_random = mean_absolute_percentage_error(y_test, y_pred_random) * 100  # 转换为百分比\n",
    "            mae_random_train = mean_absolute_error(y_train, best_model_random.predict(X_train_important))\n",
    "            mape_random_train = mean_absolute_percentage_error(y_train, best_model_random.predict(X_train_important)) * 100  # 转换为百分比\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Random Search 训练集 MAE: {mae_random_train}, MAPE: {mape_random_train}%\")\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Random Search 测试集 MAE: {mae_random}, MAPE: {mape_random}%\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - Random Search 预测失败: {str(e)}\")\n",
    "            mae_random, mape_random, mae_random_train, mape_random_train = None, None, None, None\n",
    "    else:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - Random Search 未找到最佳模型，使用原始模型的预测结果。\")\n",
    "        best_model_random = original_model\n",
    "        y_pred_random = y_pred_original\n",
    "        mae_random = mae_original\n",
    "        mape_random = mape_original\n",
    "        mae_random_train = mae_original_train\n",
    "        mape_random_train = mape_original_train\n",
    "\n",
    "    # 选择 MAE 最小的模型\n",
    "    mae_values = {}\n",
    "    if mae_original is not None:\n",
    "        mae_values['original'] = mae_original\n",
    "    if mae_grid is not None:\n",
    "        mae_values['grid_search'] = mae_grid\n",
    "    if mae_random is not None:\n",
    "        mae_values['random_search'] = mae_random\n",
    "\n",
    "    if not mae_values:\n",
    "        print(f\"Ticker {group_df['ticker'].iloc[0]} - 没有有效的 MAE 值，跳过模型选择\")\n",
    "        return None\n",
    "\n",
    "    best_model_type = min(mae_values, key=mae_values.get)\n",
    "    best_mae = mae_values[best_model_type]\n",
    "    print(f\"Ticker {group_df['ticker'].iloc[0]} - 选择的最佳模型: {best_model_type}，测试集 MAE: {best_mae}\")\n",
    "\n",
    "    if best_model_type == 'original':\n",
    "        final_predicted = y_pred_original\n",
    "    elif best_model_type == 'grid_search':\n",
    "        final_predicted = y_pred_grid\n",
    "    else:\n",
    "        final_predicted = y_pred_random\n",
    "\n",
    "    # 构建结果字典\n",
    "    result_dict = {\n",
    "        'ticker': group_df['ticker'].iloc[0],\n",
    "        'selected_features': selected_features,\n",
    "        'original_train_mae': mae_original_train,\n",
    "        'original_train_mape': mape_original_train,\n",
    "        'original_test_mae': mae_original,\n",
    "        'original_test_mape': mape_original,\n",
    "        'grid_train_mae': mae_grid_train if mae_grid_train is not None else np.nan,\n",
    "        'grid_train_mape': mape_grid_train if mape_grid_train is not None else np.nan,\n",
    "        'grid_test_mae': mae_grid if mae_grid is not None else np.nan,\n",
    "        'grid_test_mape': mape_grid if mape_grid is not None else np.nan,\n",
    "        'random_train_mae': mae_random_train if mae_random_train is not None else np.nan,\n",
    "        'random_train_mape': mape_random_train if mape_random_train is not None else np.nan,\n",
    "        'random_test_mae': mae_random if mae_random is not None else np.nan,\n",
    "        'random_test_mape': mape_random if mape_random is not None else np.nan,\n",
    "        'best_model_type': best_model_type,\n",
    "        'best_mae': best_mae,\n",
    "        'original_model': original_model,\n",
    "        'best_model_grid': best_model_grid,\n",
    "        'best_model_random': best_model_random,\n",
    "        'y_test': y_test,\n",
    "        'y_pred_original': y_pred_original,\n",
    "        'y_pred_grid': y_pred_grid if mae_grid is not None else None,\n",
    "        'y_pred_random': y_pred_random if mae_random is not None else None,\n",
    "        'test_dates': test['Date'].values,\n",
    "        'shap_values': shap_values,\n",
    "        'shap_feature_names': X_train_important.columns.tolist(),\n",
    "        'X_train_important': X_train_important,\n",
    "        'best_params_grid': best_params_grid,\n",
    "        'best_params_random': best_params_random,\n",
    "        'cv_results_grid': cv_results_grid,\n",
    "        'cv_results_random': cv_results_random,\n",
    "    }\n",
    "\n",
    "    # 筛选 shap_values 仅包含 selected_features\n",
    "    if shap_values_selected is not None:\n",
    "        try:\n",
    "            # 打印形状信息\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - shap_values_selected.shape: {shap_values_selected.shape}\")\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - X_train_important.shape: {X_train_important.shape}\")\n",
    "\n",
    "            # 确保 shap_values_selected 的样本数与 X_train_important 一致\n",
    "            if shap_values_selected.shape[0] != X_train_important.shape[0]:\n",
    "                print(f\"Ticker {group_df['ticker'].iloc[0]} - shap_values_selected 样本数与 X_train_important 不匹配\")\n",
    "                result_dict['shap_values_selected'] = None\n",
    "            else:\n",
    "                result_dict['shap_values_selected'] = shap_values_selected\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {group_df['ticker'].iloc[0]} - 筛选 shap_values 失败: {str(e)}\")\n",
    "            result_dict['shap_values_selected'] = None\n",
    "    else:\n",
    "        result_dict['shap_values_selected'] = None\n",
    "\n",
    "    # 将最终预测结果保存到结果字典中，包括实际值和最终预测值\n",
    "    predictions = pd.DataFrame({\n",
    "        'Date': test['Date'].values,\n",
    "        'ticker': group_df['ticker'].iloc[0],\n",
    "        'Actual_Return': y_test.values,\n",
    "        'Predicted_Return': final_predicted,\n",
    "        'Best_Model': best_model_type\n",
    "    })\n",
    "    result_dict['predictions'] = predictions\n",
    "\n",
    "    return result_dict\n",
    "\n",
    "# 初始化结果列表\n",
    "results = []\n",
    "\n",
    "# 按照 'ticker' 分组\n",
    "grouped = df.groupby('ticker')\n",
    "\n",
    "for name, group in grouped:\n",
    "    print(f\"\\n正在处理 Ticker: {name}\")\n",
    "    result = train_and_predict_single_ticker(\n",
    "        group,\n",
    "        shap_threshold=0.85,          # 您可以更改 shap_threshold 的值\n",
    "        use_feature_selection=False    # 设置为 True，进行特征选择；设置为 False，不进行特征选择\n",
    "    )\n",
    "    if result is not None:\n",
    "        results.append(result)\n",
    "\n",
    "# 将所有预测结果合并\n",
    "if results:\n",
    "    all_predictions = pd.concat([res['predictions'] for res in results], ignore_index=True)\n",
    "\n",
    "    # 确保日期格式正确\n",
    "    all_predictions['Date'] = pd.to_datetime(all_predictions['Date'])\n",
    "\n",
    "    # 保存预测结果为 CSV 文件（可选）\n",
    "    all_predictions.to_csv('predictions.csv', index=False)\n",
    "    print(\"\\n所有预测结果已保存为 'predictions.csv'\")\n",
    "else:\n",
    "    print(\"没有任何预测结果被生成。\")\n",
    "\n",
    "# 绘制 SHAP 图\n",
    "shap.initjs()\n",
    "\n",
    "for res in results:\n",
    "    ticker = res['ticker']\n",
    "    shap_values_selected = res['shap_values_selected']  # 使用筛选后的 shap_values\n",
    "    feature_names = res['shap_feature_names']\n",
    "    X_train_important = res['X_train_important']\n",
    "\n",
    "    print(f\"\\n绘制 Ticker {ticker} 的 SHAP 图\")\n",
    "\n",
    "    # 打印 SHAP 值和数据矩阵的形状\n",
    "    if shap_values_selected is not None:\n",
    "        print(f\"Ticker {ticker} - shap_values_selected.shape: {shap_values_selected.shape}\")\n",
    "        print(f\"Ticker {ticker} - X_train_important.shape: {X_train_important.shape}\")\n",
    "\n",
    "    # 绘制 SHAP summary plot\n",
    "    if shap_values_selected is not None and X_train_important.shape[0] > 0:\n",
    "        try:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_values_selected, X_train_important, feature_names=feature_names, show=False)\n",
    "            plt.title(f\"Ticker {ticker} - SHAP Summary Plot\")\n",
    "            plt.savefig(f'shap_summary_{ticker}.png', dpi=300)\n",
    "            plt.close()\n",
    "            print(f\"保存 Ticker {ticker} 的 SHAP Summary Plot 为 'shap_summary_{ticker}.png'\")\n",
    "\n",
    "            # 绘制 SHAP bar plot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            shap.summary_plot(shap_values_selected, X_train_important, feature_names=feature_names, plot_type=\"bar\", show=False)\n",
    "            plt.title(f\"Ticker {ticker} - SHAP Feature Importance\")\n",
    "            plt.savefig(f'shap_bar_{ticker}.png', dpi=300)\n",
    "            plt.close()\n",
    "            print(f\"保存 Ticker {ticker} 的 SHAP Feature Importance 图为 'shap_bar_{ticker}.png'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ticker {ticker} 的 SHAP 绘图失败: {str(e)}\")\n",
    "    else:\n",
    "        print(f\"Ticker {ticker} 的 SHAP 值计算失败，无法绘制 SHAP 图\")\n",
    "\n",
    "    # 绘制预测值与真实值的比较图\n",
    "    predictions = res['predictions']\n",
    "    if predictions is not None and not predictions.empty:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        plt.plot(predictions['Date'], predictions['Actual_Return'], label='Actual Return', marker='o')\n",
    "        plt.plot(predictions['Date'], predictions['Predicted_Return'], label='Predicted Return', marker='x')\n",
    "        plt.xlabel('Date')\n",
    "        plt.ylabel('Return')\n",
    "        plt.title(f'Ticker {ticker} - Actual vs Predicted Returns')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'actual_vs_predicted_{ticker}.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"保存 Ticker {ticker} 的 Actual vs Predicted Returns 图为 'actual_vs_predicted_{ticker}.png'\")\n",
    "    else:\n",
    "        print(f\"Ticker {ticker} 没有足够的数据绘制 Actual vs Predicted Returns 图\")\n",
    "\n",
    "    # 绘制预测误差分布图（可选）\n",
    "    if predictions is not None and not predictions.empty:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        error = predictions['Actual_Return'] - predictions['Predicted_Return']\n",
    "        plt.hist(error, bins=30, edgecolor='k', alpha=0.7)\n",
    "        plt.xlabel('Prediction Error (Actual - Predicted)')\n",
    "        plt.ylabel('Frequency')\n",
    "        plt.title(f'Ticker {ticker} - Prediction Error Distribution')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'prediction_error_distribution_{ticker}.png', dpi=300)\n",
    "        plt.close()\n",
    "        print(f\"保存 Ticker {ticker} 的 Prediction Error Distribution 图为 'prediction_error_distribution_{ticker}.png'\")\n",
    "\n",
    "# 输出每个 ticker 的 MAE、MAPE 和最佳模型类型\n",
    "for res in results:\n",
    "    ticker = res['ticker']\n",
    "    print(f\"\\n=== {ticker} 的模型性能 ===\")\n",
    "    print(f\"原始模型训练集 MAE: {res['original_train_mae']}, MAPE: {res['original_train_mape']}%\")\n",
    "    print(f\"原始模型测试集 MAE: {res['original_test_mae']}, MAPE: {res['original_test_mape']}%\")\n",
    "    print(f\"Grid Search 调优模型训练集 MAE: {res['grid_train_mae']}, MAPE: {res['grid_train_mape']}%\")\n",
    "    print(f\"Grid Search 调优模型测试集 MAE: {res['grid_test_mae']}, MAPE: {res['grid_test_mape']}%\")\n",
    "    print(f\"Random Search 调优模型训练集 MAE: {res['random_train_mae']}, MAPE: {res['random_train_mape']}%\")\n",
    "    print(f\"Random Search 调优模型测试集 MAE: {res['random_test_mae']}, MAPE: {res['random_test_mape']}%\")\n",
    "    print(f\"最佳模型类型: {res['best_model_type']}\")\n",
    "    print(f\"最佳模型测试集 MAE: {res['best_mae']}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
